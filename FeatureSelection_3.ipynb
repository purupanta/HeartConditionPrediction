{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+PH6pBi7yNmXjkRDqtqsE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install --upgrade tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"vyi3k6EJ4T5W","executionInfo":{"status":"ok","timestamp":1732644521419,"user_tz":360,"elapsed":77550,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"outputId":"da407eb1-79ae-4beb-d9eb-df43533f4b1e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Collecting tensorflow\n","  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n","  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard, tensorflow\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.1\n","    Uninstalling tensorboard-2.17.1:\n","      Successfully uninstalled tensorboard-2.17.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.1\n","    Uninstalling tensorflow-2.17.1:\n","      Successfully uninstalled tensorflow-2.17.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorboard-2.18.0 tensorflow-2.18.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n","from sklearn.preprocessing import StandardScaler\n","from imblearn.over_sampling import SMOTE\n","import matplotlib.pyplot as plt"],"metadata":{"id":"u3VCBlZu4Obz","executionInfo":{"status":"ok","timestamp":1732644530103,"user_tz":360,"elapsed":8701,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load the dataset\n","def load_data():\n","  data_file = 'drive/MyDrive/Colab Notebooks/HINTS/hints6_public.xlsx'\n","  # prompt: link google drive\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  # Load the dataset\n","  data = pd.read_excel(data_file)\n","  print('Data Size: ' + str(data.size) + ' Data Shape: ' + str(data.shape))\n","  return data"],"metadata":{"id":"VocflKZV6hmd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["orig_data = load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2kq5Xxnqac1","executionInfo":{"status":"ok","timestamp":1732590457885,"user_tz":360,"elapsed":126322,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"outputId":"d14059f0-b2d0-4a3f-ea1d-ecc2ed35542c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Data Size: 2982204 Data Shape: (6252, 477)\n"]}]},{"cell_type":"markdown","source":["**Boruta and LASSO**"],"metadata":{"id":"ns0BXtP3uk2F"}},{"cell_type":"code","source":["data = orig_data.copy()"],"metadata":{"id":"rLXMEV6Yx70-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Target column\n","target_column = 'MedConditions_HeartCondition'\n","\n","# Filter out invalid target values (-7 and -9)\n","data_cleaned = data[data[target_column].isin([1, 2])]\n","\n","# Map target values to binary classification: {2: 0 (No), 1: 1 (Yes)}\n","data_cleaned[target_column] = data_cleaned[target_column].map({2: 0, 1: 1})\n","\n","# Checking the cleaned target variable\n","print(data_cleaned[target_column].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwBgQWECyDGz","executionInfo":{"status":"ok","timestamp":1732593357037,"user_tz":360,"elapsed":140,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"outputId":"1f9ab2d0-eee3-488d-c519-2e02caeba9d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MedConditions_HeartCondition\n","0    5407\n","1     607\n","Name: count, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-10-4a8afb8a0b38>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned[target_column] = data_cleaned[target_column].map({2: 0, 1: 1})\n"]}]},{"cell_type":"code","source":["# Splitting features and target variable\n","X = data_cleaned.drop(columns=[target_column])  # Features\n","y = data_cleaned[target_column]  # Target\n","\n","# Separate numeric and non-numeric columns\n","X_NumericCol = X.select_dtypes(include=['float64', 'int64']).columns\n","X_NonNumericCol = X.select_dtypes(exclude=['float64', 'int64']).columns\n","\n","print(f\"Numeric columns: {len(X_NumericCol)}\")\n","print(f\"Non-numeric columns: {len(X_NonNumericCol)}\")\n","\n","# Option 1: Drop non-numeric columns (if irrelevant or challenging to encode)\n","X_prepared = X[X_NumericCol]\n","\n","# Option 2: One-hot encode non-numeric columns (if relevant for modeling)\n","# Uncomment the following if you want to encode instead of dropping:\n","# X_non_numeric_encoded = pd.get_dummies(X[non_numeric_columns], drop_first=True)\n","# X_prepared = pd.concat([X[numeric_columns], X_non_numeric_encoded], axis=1)\n","\n","# Display the final prepared dataset structure\n","print(X_prepared.info())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srNJ_Ie7yn_9","executionInfo":{"status":"ok","timestamp":1732593655922,"user_tz":360,"elapsed":200,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"outputId":"71795b2b-d4d7-41a5-878f-eaa2bdc7c90f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Numeric columns: 463\n","Non-numeric columns: 13\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 6014 entries, 0 to 6251\n","Columns: 463 entries, HHID to IncomeRanges_IMP\n","dtypes: float64(58), int64(405)\n","memory usage: 21.3 MB\n","None\n"]}]},{"cell_type":"code","source":["# Step 3: Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_NumericCol, y, test_size=0.3, random_state=42)\n","\n","# Step 4: Handle missing values (Impute missing values with the column mean)\n","imputer = SimpleImputer(strategy='mean')\n","X_train_cleaned = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n","X_test_cleaned = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n"],"metadata":{"id":"b5MJY-iMz8P3","executionInfo":{"status":"error","timestamp":1732593506896,"user_tz":360,"elapsed":122,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"colab":{"base_uri":"https://localhost:8080/","height":356},"outputId":"106d5d47-fd87-4b02-8b4c-b55006d7caca"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [463, 6014]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-aa0fd8c4a231>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 3: Split data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_NumericCol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 4: Handle missing values (Impute missing values with the column mean)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2782\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [463, 6014]"]}]},{"cell_type":"code","source":["!pip install boruta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qj1iCqL1555E","executionInfo":{"status":"ok","timestamp":1732559909509,"user_tz":360,"elapsed":9784,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"outputId":"dbca4595-4869-48fc-bf29-7733f076e736"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: boruta in /usr/local/lib/python3.10/dist-packages (0.4.3)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.5.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->boruta) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->boruta) (3.5.0)\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from boruta import BorutaPy\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","\n","# Define the Random Forest model (rf_model)\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Initialize Boruta with modified parameters\n","boruta = BorutaPy(\n","    estimator=rf_model,\n","    n_estimators='auto',\n","    random_state=42,\n","    max_iter=200,  # Increase the number of iterations\n","    alpha=0.05  # Be less strict in feature selection\n",")\n","\n","# Fit Boruta to the cleaned training data\n","boruta.fit(X_train_cleaned.values, y_train.values)\n","\n","# Get the top 10 features from Boruta\n","selected_features = X_train_cleaned.columns[boruta.support_].tolist()\n","if len(selected_features) < 10:\n","    # Add tentative features until we reach 10\n","    tentative_features = X_train_cleaned.columns[boruta.support_weak_].tolist()\n","    selected_features += tentative_features[:10 - len(selected_features)]\n","\n","print(\"Top 10 features by Boruta:\")\n","print(selected_features[:10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p44vpKKA-dSD","executionInfo":{"status":"ok","timestamp":1732560062712,"user_tz":360,"elapsed":149787,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"outputId":"9c8671b0-6d7f-4741-e295-d337208d60ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 features by Boruta:\n","['Age']\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","from sklearn.feature_selection import SelectFromModel\n","import numpy as np\n","\n","# Define the Lasso model with cross-validated alpha for regularization\n","lasso = Lasso(alpha=0.01, random_state=42, max_iter=10000)  # Adjust alpha for stricter/looser selection\n","\n","# Fit Lasso on the training data\n","lasso.fit(X_train_cleaned, y_train)\n","\n","# Use SelectFromModel to automatically select features with non-zero coefficients\n","model = SelectFromModel(lasso, prefit=True)\n","\n","# Get the selected features\n","selected_features = X_train_cleaned.columns[model.get_support()].tolist()\n","\n","# If fewer than 10 features are selected, take the top by absolute coefficient magnitude\n","if len(selected_features) < 10:\n","    lasso_coefficients = np.abs(lasso.coef_)\n","    feature_ranking = np.argsort(lasso_coefficients)[::-1]  # Sort by descending coefficient magnitude\n","    additional_features = X_train_cleaned.columns[feature_ranking].tolist()\n","    selected_features = list(set(selected_features + additional_features[:10 - len(selected_features)]))\n","\n","print(\"Top 10 features by Lasso:\")\n","print(selected_features[:10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgFqcSXKuC4x","executionInfo":{"status":"ok","timestamp":1732561677996,"user_tz":360,"elapsed":56453,"user":{"displayName":"Purushottam Panta","userId":"07841139357751360450"}},"outputId":"711ffadb-d3e8-406e-9532-f5ea4b57ddf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 features by Lasso:\n","['APP_REGION', 'VAR_CLUSTER', 'MAILHHADULTS', 'CancerTrustFamily', 'CancerTrustCharities', 'HAVEDEVICE_CAT', 'UsedHealthWellnessApps2', 'SocMed_Visited', 'SocMed_WatchedVid', 'SocMed_MakeDecisions']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+02, tolerance: 3.773e-02\n","  model = cd_fast.enet_coordinate_descent(\n"]}]}]}